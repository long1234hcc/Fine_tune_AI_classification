{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Thay file path\n",
    "file_input_path = \"butbi_cleaned_250624.xlsx\"\n",
    "base_image_input = \"images_butbi\"\n",
    "model_save_path = \"model_classification_butbi\"\n",
    "num_classes = \"num_classes.txt\"\n",
    "file_output_after_download_images_test = \"output.xlsx\"\n",
    "otput_file = \"but_bi_2008_AI_AT.xlsx\"\n",
    "output_file_path_name = \"VIT_AI_butbi.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Bước 1: Tải ảnh (thay file path + thay tên folder ảnh + thay cột brand_gop(nếu cần) )\n",
    "import os\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "# Đọc dữ liệu huấn luyện\n",
    "file_path = file_input_path\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Tạo thư mục lưu trữ ảnh và các thư mục con tương ứng với thương hiệu\n",
    "base_image_folder = base_image_input\n",
    "os.makedirs(base_image_folder, exist_ok=True)\n",
    "\n",
    "# Tải ảnh xuống các thư mục con tương ứng với thương hiệu\n",
    "def download_images(df, base_image_folder):\n",
    "    def fetch_image(idx, row):\n",
    "        img_url = row['url_thumbnail']\n",
    "        brand = row['brand_clean'].replace(' ', '_').lower()\n",
    "        brand_folder = os.path.join(base_image_folder, brand)\n",
    "        os.makedirs(brand_folder, exist_ok=True)\n",
    "        try:\n",
    "            response = requests.get(img_url)\n",
    "            response.raise_for_status()  # Kiểm tra nếu yêu cầu không thành công\n",
    "            img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "            img.save(os.path.join(brand_folder, f\"{idx}.jpg\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading image at index {idx}: {e}\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=30) as executor:\n",
    "        list(tqdm(executor.map(lambda idx: fetch_image(idx, df.iloc[idx]), range(len(df))), total=len(df), desc='Downloading Images'))\n",
    "\n",
    "download_images(data, base_image_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "\n",
    "\n",
    "\n",
    "# Đọc dữ liệu huấn luyện\n",
    "data = pd.read_excel(file_input_path)\n",
    "\n",
    "def normalized(text):\n",
    "    if text is None:\n",
    "        return ''\n",
    "    elif type(text) is not str:\n",
    "        return str(text)\n",
    "    else:\n",
    "        return text.lower().strip()\n",
    "\n",
    "data['brand_clean'] = data['brand_clean'].apply(normalized)\n",
    "\n",
    "# Chuẩn bị dữ liệu\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, folder_image_path: str, transform=None):\n",
    "        self.data = dataframe\n",
    "        self.transform = transform\n",
    "        self.folder_image_path = folder_image_path\n",
    "        self.classes = sorted(self.data['brand_clean'].unique())\n",
    "        self.class_to_idx = {cls.replace(' ', '_').lower(): idx for idx, cls in enumerate(self.classes)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        brand = self.data.iloc[idx]['brand_clean'].replace(' ', '_').lower()\n",
    "        image_path = os.path.join(self.folder_image_path, brand, f\"{self.data.index[idx]}.jpg\")\n",
    "        if not os.path.exists(image_path):\n",
    "            return torch.zeros((3, 224, 224)), -1\n",
    "\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image at {image_path}: {e}\")\n",
    "            return torch.zeros((3, 224, 224)), -1\n",
    "        \n",
    "        label_idx = self.class_to_idx[brand]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label_idx\n",
    "\n",
    "print('Preparing dataset...')\n",
    "df = data[(data['brand_clean'].notnull())]\n",
    "df['brand_clean'] = df['brand_clean'].str.replace(' ', '_').str.lower()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "custom_dataset = CustomDataset(dataframe=df, transform=transform, folder_image_path=base_image_input)\n",
    "print(f'Loaded full dataset with {len(custom_dataset)} samples.')\n",
    "\n",
    "# Extract all indices from the DataLoader\n",
    "indices = list(range(len(custom_dataset)))\n",
    "\n",
    "# Split indices into train, valid, and test sets\n",
    "if len(indices) == 0:\n",
    "    raise ValueError(\"No valid indices found. Ensure that the dataset is not empty.\")\n",
    "\n",
    "train_indices, remaining_indices = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "if len(train_indices) == 0:\n",
    "    raise ValueError(\"Train set is empty after splitting. Adjust test_size or ensure more data is available.\")\n",
    "\n",
    "valid_indices, test_indices = train_test_split(remaining_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "# Check number of samples in each split\n",
    "print(f'Number of train samples: {len(train_indices)}')\n",
    "print(f'Number of valid samples: {len(valid_indices)}')\n",
    "print(f'Number of test samples: {len(test_indices)}')\n",
    "\n",
    "# Create Subset and DataLoader for each set\n",
    "BATCH_SIZE = 6\n",
    "\n",
    "# Lọc các phần tử không hợp lệ trước khi tạo DataLoader\n",
    "def collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x[1] != -1, batch))\n",
    "    if len(batch) == 0:\n",
    "        return torch.zeros((0, 3, 224, 224)), torch.zeros((0,), dtype=torch.long)\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "train_loader = DataLoader(Subset(custom_dataset, train_indices), batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(Subset(custom_dataset, valid_indices), batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(Subset(custom_dataset, test_indices), batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "print(\"Number of train samples: \", len(train_indices))\n",
    "print(\"Number of valid samples: \", len(valid_indices))\n",
    "print(\"Number of test samples: \", len(test_indices))\n",
    "print(\"Detected Classes are: \", len(custom_dataset.classes), \"labels\")\n",
    "\n",
    "# google/vit-huge-patch14-224-in21k\n",
    "# google/vit-base-patch16-224\n",
    "# Define the model class\n",
    "class ViTForImageClassification2(nn.Module):\n",
    "    def __init__(self, num_labels=10):\n",
    "        super(ViTForImageClassification2, self).__init__()\n",
    "        # self.vit = ViTModel.from_pretrained('google/vit-base-patch16-224')\n",
    "        self.vit = ViTModel.from_pretrained(\"google/vit-large-patch16-224-in21k\")\n",
    "\n",
    "        self.classifier = nn.Linear(self.vit.config.hidden_size, num_labels)\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "\n",
    "    def forward(self, images):\n",
    "        outputs = self.vit(pixel_values=images)\n",
    "        logits = self.classifier(outputs.last_hidden_state[:, 0])\n",
    "        return logits\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = ViTForImageClassification2(num_labels=len(custom_dataset.classes))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device\",device)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    corrects = (preds == labels).sum().item()\n",
    "    return corrects / len(labels)\n",
    "\n",
    "\n",
    "best_val_loss  = 999\n",
    "# Train the model\n",
    "EPOCHS = 6\n",
    "for epoch in tqdm(range(EPOCHS),\"Processs...\"):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for images, labels in train_loader:\n",
    "        if len(images) == 0:\n",
    "            continue\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += calculate_accuracy(outputs, labels) * len(labels)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = running_corrects / len(train_indices)\n",
    "    \n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            if len(images) == 0:\n",
    "                continue\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            val_corrects += calculate_accuracy(outputs, labels) * len(labels)\n",
    "    \n",
    "    val_loss = val_loss / len(valid_loader)\n",
    "    val_acc = val_corrects / len(valid_indices)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        # # Lưu mô hình\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved at {model_save_path}\")\n",
    "        num_classes = len(custom_dataset.classes)\n",
    "        with open(\"num_classes.txt\", \"w\") as f:\n",
    "            f.write(str(num_classes))\n",
    "        print(f\"Number of classes saved at num_classes.txt\")\n",
    "\n",
    "\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}, Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_acc:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from transformers import ViTForImageClassification, ViTConfig\n",
    "\n",
    "# Đọc dữ liệu dự đoán\n",
    "test_file_path = otput_file\n",
    "test_data = pd.read_excel(test_file_path)\n",
    "\n",
    "# Tạo thư mục lưu trữ ảnh\n",
    "test_image_folder = \"imgaes_base_output\"\n",
    "os.makedirs(test_image_folder, exist_ok=True)\n",
    "\n",
    "# Hàm tải ảnh\n",
    "def download_image(row):\n",
    "    img_url = row['url_thumbnail']\n",
    "    img_id = str(row['product_base_id'])  # Sử dụng trường \"id\" để đặt tên tệp ảnh\n",
    "    img_path = os.path.join(test_image_folder, f\"{img_id}.jpg\")\n",
    "    try:\n",
    "        response = requests.get(img_url)\n",
    "        response.raise_for_status()\n",
    "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        img.save(img_path)\n",
    "        return img_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image {img_url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Tải ảnh xuống thư mục\n",
    "print(\"Downloading test images...\")\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    image_paths = list(tqdm(executor.map(download_image, [row for _, row in test_data.iterrows()]), total=len(test_data), desc='Downloading Test Images'))\n",
    "\n",
    "# Loại bỏ các hàng không tải được ảnh\n",
    "test_data['image_path'] = image_paths\n",
    "test_data = test_data.dropna(subset=['image_path']).reset_index(drop=True)\n",
    "\n",
    "print(\"Finished downloading test images.\")\n",
    "\n",
    "# Tạo lớp Dataset cho dữ liệu test\n",
    "class TestBrandDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['image_path']\n",
    "        \n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"File not found: {img_path}\")\n",
    "        \n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "\n",
    "## Save test data \n",
    "\n",
    "test_data.to_excel(file_output_after_download_images_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from transformers import ViTForImageClassification, ViTConfig\n",
    "\n",
    "\n",
    "test_data = pd.read_excel(file_output_after_download_images_test)\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, folder_image_path: str, transform=None):\n",
    "        self.data = dataframe\n",
    "        self.transform = transform\n",
    "        self.folder_image_path = folder_image_path\n",
    "        self.classes = sorted(self.data['brand_clean'].unique())\n",
    "        self.class_to_idx = {cls.replace(' ', '_').lower(): idx for idx, cls in enumerate(self.classes)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        brand = self.data.iloc[idx]['brand_clean'].replace(' ', '_').lower()\n",
    "        image_path = os.path.join(self.folder_image_path, brand, f\"{self.data.index[idx]}.jpg\")\n",
    "        if not os.path.exists(image_path):\n",
    "            return torch.zeros((3, 224, 224)), -1\n",
    "\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image at {image_path}: {e}\")\n",
    "            return torch.zeros((3, 224, 224)), -1\n",
    "        \n",
    "        label_idx = self.class_to_idx[brand]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label_idx\n",
    "    \n",
    "class TestBrandDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['image_path']\n",
    "        \n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"File not found: {img_path}\")\n",
    "        \n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "\n",
    "# Chuẩn bị dữ liệu test\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "test_dataset = TestBrandDataset(test_data, transform=test_transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Kiểm tra xem có GPU hay không\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Sử dụng số lượng lớp từ custom_dataset\n",
    "# num_labels = len(custom_dataset.classes)\n",
    "\n",
    "with open(\"num_classes.txt\", \"r\") as f:\n",
    "    num_classes = int(f.read().strip())\n",
    "print(f\"Number of classes loaded: {num_classes}\")\n",
    "\n",
    "# google/vit-base-patch16-224\n",
    "# google/vit-large-patch16-224-in21k\n",
    "# Khởi tạo cấu hình mô hình\n",
    "config = ViTConfig.from_pretrained('google/vit-large-patch16-224-in21k', num_labels=num_classes)\n",
    "\n",
    "# Tạo và dự đoán với mô hình đã huấn luyện\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-large-patch16-224-in21k', config=config)\n",
    "\n",
    "# Tải trạng thái mô hình đã lưu\n",
    "state_dict = torch.load(model_save_path)\n",
    "\n",
    "# Lọc các khóa không mong muốn\n",
    "filtered_state_dict = {k: v for k, v in state_dict.items() if k in model.state_dict()}\n",
    "\n",
    "custom_dataset = CustomDataset(dataframe=df, transform=transform, folder_image_path=base_image_input)\n",
    "\n",
    "\n",
    "model.load_state_dict(filtered_state_dict, strict=False)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "scores = []\n",
    "print(\"Predicting...\")\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(test_dataloader, desc='Predicting'):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images).logits\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        scores.extend(torch.softmax(outputs, dim=1).max(dim=1).values.cpu().numpy())\n",
    "\n",
    "# Giải mã nhãn và lưu kết quả\n",
    "decoded_predictions = [str(custom_dataset.classes[pred]).replace(\"_\",\" \") for pred in predictions]\n",
    "\n",
    "test_data['predicted_brand'] = decoded_predictions\n",
    "test_data['score'] = scores\n",
    "print(\"Export files\")\n",
    "output_file_path = output_file_path_name\n",
    "test_data.to_excel(output_file_path, index=False)\n",
    "print(f\"Kết quả dự đoán đã được lưu vào '{output_file_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
